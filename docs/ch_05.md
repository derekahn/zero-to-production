# Chapter 5

## Goals

- [x] Containerization
- [x] Setup DigitalOcean
- [ ] CI/CD Pipeline

## Dockerfile

Due to how sqlx does a compile time check against a live database connection via `DATABASE_URL` we'll need to adjust for containerization.

```sh
# It must be invoked as a cargo subcommand
# All options after `--` are passed to cargo itself
# We need to point it at our library since it contains
# all our SQL queries.
cargo sqlx prepare -- --lib
```

The above didn't work for me, so I had to re-install it:

```sh
cargo install sqlx-cli && cargo sqlx prepare -- --lib
    Checking zero2prod v0.1.0 (/code/zero-to-production)
    Finished dev [unoptimized + debuginfo] target(s) in 1.87s
query data written to `sqlx-data.json` in the current directory; please check this into version control
```

which output this file in my root as `sqlx-data.json`:

```json
{
  "db": "PostgreSQL",
  "4b0ad859d2b54b0e4b34d2b56b993d973001526cc4ae39f99abfcc3f94d4a91d": {
    "describe": {
      "columns": [],
      "nullable": [],
      "parameters": {
        "Left": ["Uuid", "Text", "Text", "Timestamptz"]
      }
    },
    "query": "\n    INSERT INTO subscriptions (id, email, name, subscribed_at)\n    VALUES ($1, $2, $3, $4)\n        "
  }
}
```

### Binary Size

When it comes to deployment and containerization size matters, and we want the smallest image possible and other than performing multi-stage docker builds to free up env/os bloat and cruft the next thing we can focus on is binary size.

By default on Linux and macOS, symbol information is included in the compiled `.elf` file. This
information is not needed to properly execute the binary.

Cargo can be configured to
[automatically `strip` binaries](https://doc.rust-lang.org/cargo/reference/profiles.html#strip).
Modify `Cargo.toml` in this way:

```toml
# Cargo.toml
[profile.release]
strip = true  # Automatically strip symbols from the binary.
```

[Cargo defaults its optimization level to `3` for release builds][cargo-profile],
which optimizes the binary for **speed**. To instruct Cargo to optimize for minimal binary
**size**, use the `z` optimization level in
[`Cargo.toml`](https://doc.rust-lang.org/cargo/reference/manifest.html):

```toml
# Cargo.toml
[profile.release]
opt-level = "z"  # Optimize for size.
```

### Multi-stage Builds

Leveraging multi-stage builds with Luca's base image [cargo-chef](https://github.com/LukeMathWalker/cargo-chef) which leverages docker caching.

i.e.

```Dockerfile
FROM lukemathwalker/cargo-chef:latest-rust-1.65.0 as chef

ENV SQLX_OFFLINE true
WORKDIR /app
RUN apt update && apt install lld clang -y

FROM chef as planner

COPY . .
# Compute a lock-like file for our project
RUN cargo chef prepare  --recipe-path recipe.json
FROM chef as builder
COPY --from=planner /app/recipe.json recipe.json
# Build our project dependencies, not our application!
RUN cargo chef cook --release --recipe-path recipe.json
# Up to this point, if our dependency tree stays the same,
# all layers should be cached.
COPY . .
RUN cargo build --release --bin zero2prod

FROM debian:bullseye-slim AS runtime
WORKDIR /app

RUN apt-get update -y \
  && apt-get install -y --no-install-recommends openssl ca-certificates \
  && apt-get autoremove -y \
  && apt-get clean -y \
  && rm -rf /var/lib/apt/lists/*

COPY --from=builder /app/target/release/zero2prod zero2prod
COPY configuration configuration

ENV APP_ENVIRONMENT production
ENTRYPOINT ["./zero2prod"]
```

Luca's base image appears to be a nice balance between compilation and docker build speed and a finalized image size that's a magnitude smaller. However, I don't like depending on non-official base images.

Personally, I would prefer a final image to be `scratch` or `alpine`. I prefer to sacrifice compile and build speed for smaller size and security.

#### üöß üí°:

Something around the lines ü§∑üèΩ‚Äç‚ôÇÔ∏è:

```Dockerfile
FROM rust:1.65.0 AS builder

ENV SQLX_OFFLINE true
ENV RUST_BACKTRACE 1

WORKDIR /app

COPY . .

RUN apt update \
  && apt upgrade -y \
  && apt install lld clang -y \
  && rustup target add x86_64-unknown-linux-musl \
  && cargo build --release \
  && cargo install --target x86_64-unknown-linux-musl --path .

FROM scratch AS final

ENV APP_ENVIRONMENT production

COPY --from=builder /app/zero2prod .

EXPOSE 8000
USER 1000

ENTRYPOINT [ "./zero2prod" ]
```

## Digital Ocean

First [create API Token](https://cloud.digitalocean.com/account/api/tokens)

```sh
# install digitial ocean CLI
brew install doctl

# add API token
doctl auth init
  Enter your access token:
  ...
  Validating token... OK

# double check
doctl account get
  User Email             Team       Droplet Limit    Email Verified    User UUID                               Status
  user_name@email.com    My Team    10               true              a1eac88d-xxxx-xxxx-xxxx-xxxxxxxxxxxx    active
```

Add initial `spec.yaml` in root:

```yaml
name: zero2prod
# `sfo3` stands for San Francisco
region: sfo3
services:
  - name: zero2prod
    # Relative to the repository root
    dockerfile_path: Dockerfile
    source_dir: .
    github:
      # Depending on when you created the repository,
      # the default branch on GitHub might have been named `master`
      branch: main
      # Deploy a new version on every commit to `main`!
      # Continuous Deployment, here we come!
      deploy_on_push: true
      # !!! Fill in with your details
      # e.g. LukeMathWalker/zero-to-production
      repo: <YOUR USERNAME>/<YOUR REPOSITORY NAME>
    # Active probe used by DigitalOcean's to ensure our application is healthy
    health_check:
      # The path to our health check endpoint!
      # It turned out to be useful in the end!
      http_path: /health_check
    # The port the application will be listening on for incoming requests
    # It should match what we specified in our configuration/production.yaml file!
    http_port: 8000
    # For production workloads we'd go for at least two!
    # But let's try to keep the bill under control for now...
    instance_count: 1
    instance_size_slug: basic-xxs
    # All incoming requests should be routed to our app
    routes:
      - path: /
    envs:
      - key: APP_DATABASE__USERNAME
        scope: RUN_TIME
        value: ${newsletter.USERNAME}
      - key: APP_DATABASE__PASSWORD
        scope: RUN_TIME
        value: ${newsletter.PASSWORD}
      - key: APP_DATABASE__HOST
        scope: RUN_TIME
        value: ${newsletter.HOSTNAME}
      - key: APP_DATABASE__PORT
        scope: RUN_TIME
        value: ${newsletter.PORT}
      - key: APP_DATABASE__DATABASE_NAME
        scope: RUN_TIME
        value: ${newsletter.DATABASE}
databases:
  # PG = Postgres
  - engine: PG
    name: newsletter
    num_nodes: 1
    # The cheapest one
    size: db-s-dev-database
    version: "12"
```

First make sure your github's oAuth has access to the repo(s) and you've [linked github to digital ocean](https://cloud.digitalocean.com/apps/github/install)

You can spin it up with the `doctl` (kind of like terraform):

```sh
doctl apps create --spec spec.yaml
  Notice: App created
  ID                                      Spec Name    Default Ingress    Active Deployment ID    In Progress Deployment ID    Created At                                 Updated At
  1c612dff-9411-45a5-8be3-23dff74e9376    zero2prod                                                                            2022-12-16 04:25:05.886718549 +0000 UTC    2022-12-16 04:25:05.886718549 +0000 UTC
```

I initially had trouble finding the digital ocean database settings:

![DATABASE_URL](../assets/DATABASE_URL.png)

A connection string:

```sh
postgresql://newsletter:AVNS_fmPst2_xxxxxxxxxxxx@app-54b2e929-xxxx-xxxx-xxxx-xxxxxxxxxxxx-do-user-13110253-0.b.db.ondigitalocean.com:25060/newsletter?sslmode=require
```

Security was enabled on the database by default and I spent a long time looking for the TLS certs for the dev (cheap) database version we're using.

Ended up disabling the security by default so that we can connect with username/password/host/port/db alone:

![disable db security](../assets/db_security.png)

Afterwards I was able to successfully run the migrations from local to remote database:

```sh
DATABASE_URL="postgresql://newsletter:AVNS_fmPst2_xxxxxxxxxxxx@app-54b2e929-xxxx-xxxx-xxxx-xxxxxxxxxxxx-do-user-13110253-0.b.db.ondigitalocean.com:25060/newsletter" sqlx migrate run
  Applied 20221208173628/migrate create subscriptions table (189.623942ms)
```

Moment of truth ü§ûüèΩ:

```sh
http --form POST https://zero2prod-xxxxx.ondigitalocean.app/subscriptions \
  name="iam groot" \
  email="iam@groot.com"

HTTP/1.1 200 OK
CF-Cache-Status: DYNAMIC
CF-RAY: 77a9bf385e9cc735-SEA
Connection: keep-alive
Content-Length: 0
Date: Fri, 16 Dec 2022 19:15:18 GMT
Server: cloudflare
cache-control: private
x-do-app-origin: 14183d5d-fa68-40ce-b7b7-622c2b91157b
x-do-orig-status: 200
```
